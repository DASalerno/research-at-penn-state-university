Penn-State

This repository contains samples of my contributions to research projects I volunteered on at Penn State University under Dr. Matthew Carlson and Dr. Katrina Connell.

  The projects directed by Dr. Connell (_Pirate Project_ and _FOAN Project_) all had some overlapping elements: (1) they used eye-movement data, and (2) they examined the role of linguistic variables during prediction in language comprehension. In the most common version of the experiments, participants were instructed to listen to a sentence (e.g., “Click on the image of an orange”) while viewing four images on a computer screen (e.g., an orange, the ‘target;’ a chair, the ‘competitor;’ two ants, and three turtles, the ‘distracters’). The question of interest was whether the presence of a linguistic cue (in the example above, the indefinite article an) in the instruction would trigger looks to the target (i.e., orange) before it was heard in the speech stream. The dependent variable in these studies was the proportion of fixations to the target image relative to the other images on the visual display.
  
  For the projects, I pre-processed the data and conducted exploratory analysis in R. I extracted raw data frames that specified the location of the targets, competitors and distracters for each trial, created matrices that also contained participant-specific information—such as age, native language, age of first and second language acquisition, and language proficiency— and coded the responses collected from several individual-difference measures (e.g., category fluency and picture naming tasks used to determine language proficiency in Spanish). In addition to recording participant responses in these tasks, I searched for coding errors in the list of accepted responses and suggested improvements. I processed the data by altering and confirming data types, checking for and removing duplicate data, filtering out missing data, filtering out invalid responses, and excluding data outside of the designated interest periods. I also grouped the data by trial, participant, and interest period, and added the proportion of fixations to each location. After calculating the proportion of fixations in each trial, Dr. Connell and I explored the data by examining summary statistics and creating visualizations of the proportions across the various interest periods, often faceted by certain individual-difference measures of interest such as language proficiency. 
  
  On a different project examining the so-called “cognate effect” (the finding that words that are similar in form and meaning such as elefante in Spanish and elephant in English are recognized faster than non-cognate words), I coded response times in picture naming tasks using the speech analysis program Praat. I created various visualizations of the data and used the statistical knowledge that I had recently gained in Dr. Carlson's course Current Statistical Practice in Language Science to build a model of the cognate effect. I ran a multiple regression structure that measured the mean-centered log response times against condition (cognate or non-cognate) and age (also mean-centered). Experimental condition and age were allowed to interact with the participant code and item code, respectively.
  
  I am currently assisting Dr. Carlson in a speech production research project that seeks to identify pronunciation errors among first- and second-language Basque speakers via a systemic phonetic analysis. We are waiting for the collection of additional data needed to begin to analyze the primary data, which consists of text grids from interviews conducted with participants in Basque. To briefly explain, text grids consist of multiple text tiers (i.e., sentence, word, pronunciation) that are time-aligned with the moment in the interview in which they are spoken. My contribution to this project thus far has been primarily related to the production of these text grids and their alignment with the audio files. When I was first introduced to the project, Dr. Carlson and one of his undergraduate students were troubleshooting an issue related to the dictionary that would be used to create the text grids. The dictionary, containing the words found in the transcripts of the interviews, was inputted into a program that produced a .csv file with two columns: one with the list of words, and the other with their corresponding pronunciation. One task assigned to me was to solve a misalignment issue caused by the program: certain characters in the dictionary were causing the merging of two pronunciations into one. Despite having no prior knowledge of Basque, I was able to recognize the patterns of pronunciation in the dictionary, distinguish the instances in which the column was misaligned, and use this information to correct the dictionary for all similar instances. Subsequently, I familiarized myself with a terminal application called Montreal Forced Aligner to incorporate the words and their corresponding pronunciations into a text grid that contained a sentence-tier. I wrote a script in Praat that parsed two specified directories – the sentence-tier grids and word/pronunciation-tier grids– for files with matching names, merged them, and saved them as new text grids to a designated final directory. I then examined the result to identify errors in the alignment process and determine the potential cause of the error in the Praat script.
